{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4a36ed59-1b92-4395-bab1-2509f76518ae",
    "_uuid": "95e1df618273182dce3c07c4e5d316c6a54f08cf"
   },
   "source": [
    "# COMP500827 机器学习在信息安全中的应用 <br> 第二次作业：支持向量机 <br> 截止日期：2024年12月22日24:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "姓名：，学号："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**作业提交要求**：\n",
    "- 务必在上面填上自己的姓名和学号\n",
    "- 提交内容应包括：以jupyter notebook形式编写的Python代码（文件后缀名为.ipynb）、带所有输出结果的jupyter notebook文件对应的PDF文件（注意：不需要把数据打包）\n",
    "- 所有文件须用zip格式打包成一个压缩包，要求解压即可运行\n",
    "- 压缩包上传至教学系统（https://class.xjtu.edu.cn/course/74005/homework#/ ）\n",
    "\n",
    "**作业迟交惩罚制度**：在截止时间前提交的作业/大实验不会遭受任何迟交惩罚。每位学生在整个课程期间有三天的延期时间，可以根据自己的需要使用。在使用这三天延期时，每延迟一天，你的作业/大实验成绩将被扣除15%。你可以根据自己的需要灵活使用这三天延期。例如，你可以将这三天全都用在一个作业/大实验上（本次作业/大实验最多只能获得55%的分数），或者分开使用，每个作业/大实验使用一天延期（每个作业/大实验的最高分为85%）。一旦你使用完这三天延期，之后提交的任何迟交作业将无法获得学分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "95f30dd3-7b08-4087-b156-5bf3250ce742",
    "_uuid": "dc31e50ac68836610ff16246bbda63d7ae6db49b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn库：SVM、分类指标等\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import itertools, math\n",
    "\n",
    "# Matplotlib库：用于画图\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "# Seaboarn库：用于数据可视化\n",
    "import seaborn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c375090-4893-4b92-ad94-abb3fbc60e22",
    "_uuid": "504f7342684d5bb9d64acbd7f48c89c2846e69a9"
   },
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集（[Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data)）包含2013年9月由欧洲持卡人通过信用卡进行的284,807笔交易。这些交易发生在两天内，其中共有492笔欺诈交易。该数据集非常不平衡，正例（欺诈交易）仅占所有交易的0.172％。\n",
    "\n",
    "由于用户信息需要保密，数据集中无法提供有关数据的原始功能和更多背景信息。给定一个交易的信息，我们需要判断这个交易是欺诈交易（标签为1），还是非欺诈交易（标签为0）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b3cd20ab-f13e-4083-9c36-9291414694c2",
    "_uuid": "232bc475856a4f5e92083e1757242020100ee284"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./creditcard.csv')\n",
    "# 二分类任务, Class = 1 (欺诈交易)；Class = 0 (非欺诈交易)\n",
    "class_names=np.array(['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae7d0f5e-f323-46f6-a454-a2a8065af693",
    "_uuid": "dda60fcd5cb9953205c5ae716fcdf7cd5682f9eb"
   },
   "source": [
    "# 数据特征可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "baeaea24-4736-473a-a85c-cbc3ddde9ed3",
    "_uuid": "9d450721809ddf6aa0754b705062bfdf837d9c54"
   },
   "outputs": [],
   "source": [
    "# 将数据转化成Pandas DataFrame，便于处理\n",
    "df = pd.DataFrame(data).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6aade7ce-2b87-4cd0-a998-3a54ac14d4df",
    "_uuid": "4eafc2bb6228637b51ba4e1c97ded7456440cd0f"
   },
   "outputs": [],
   "source": [
    "# 数据的统计特征描述（总和、平均值、方差、最小值、第1四分位数、第2四分位数、第3四分位数和最大值）\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aaf455b3-f3a1-4316-99c6-cbd4c0a8b33d",
    "_uuid": "346c8874f9118fcbcea8f028804179eed54eca69"
   },
   "outputs": [],
   "source": [
    "# 将欺诈交易数据筛选出来\n",
    "df_fraud = df[df['Class'] == 1] \n",
    "\n",
    "# 按照时间顺序显式欺诈交易金额\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(df_fraud['Time'], df_fraud['Amount'])\n",
    "plt.title('Time series of fraud amount', fontsize=20)\n",
    "plt.xlabel('Time', fontsize=20)\n",
    "plt.ylabel('Amount', fontsize=20)\n",
    "plt.xlim([0,175000])\n",
    "plt.ylim([0,2500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "970cef6c-01b8-4d61-a3b5-38c3398f9c6f",
    "_uuid": "61c0ec8f7ae47ca9514c2cf3d1e729ba7c528c4e"
   },
   "source": [
    "我们首先可以注意到，时间和欺诈发生的频率没有明显关联。此外，大多数欺诈交易金额较小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b77e909-ab26-4783-8005-bf591d66cf5b",
    "_uuid": "9a273b886643735328b0666edf70d12807804fe1"
   },
   "outputs": [],
   "source": [
    "# 筛选出欺诈交易金额超过1000的交易事件\n",
    "nb_big_fraud = df_fraud[df_fraud['Amount'] > 1000].shape[0]\n",
    "print('There are only '+ str(nb_big_fraud) + ' fraud cases where the amount was higher than 1000 over ' + str(df_fraud.shape[0]) + ' frauds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "43c05bc7-c327-4120-9a4b-9b319457a0b5",
    "_uuid": "c5b9104e688e7bcee494645969a7c8360aff515e"
   },
   "source": [
    "# 样本数据的不均衡性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "02332e68-9fec-48c5-89cd-06ce360f2e9c",
    "_uuid": "bd071ed3ed6dcf625adc45196f615d62cd462ab1"
   },
   "outputs": [],
   "source": [
    "number_fraud = len(data[data.Class == 1])\n",
    "number_no_fraud = len(data[data.Class == 0])\n",
    "print('There are only '+ str(number_fraud) + ' fraud cases in the original dataset, while there are ' + str(number_no_fraud) +' non-fraud cases.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a78cfc34-d5a4-45b7-abc1-c70dec7e1c9b",
    "_uuid": "0fa59cb4bb66a0c62d3edb6eb2650d64e19fc113"
   },
   "source": [
    "所以，这个数据集是很不平衡的。直接用这些数据训练模型可能会有两类问题：\n",
    "1. 模型可能会偏向多数类，从而导致预测少数类的性能不佳。这是因为当我们以最小化错误率为目标在这种数据集上训练模型时，多数类会被过度代表，模型倾向于更频繁地预测多数类。\n",
    "2. 当模型处理新数据时，它可能无法很好地泛化。这是因为该模型是在倾斜的数据集上训练的，可能无法处理测试数据中的不平衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c54c8f9f-9301-4a96-9c8b-1845946187ff",
    "_uuid": "a6896c291abc000d9d642fcc65bb93d45b118236"
   },
   "source": [
    "**计算分类指标**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c57ed880-9e78-4620-9158-bfe626bf75f6",
    "_uuid": "a484397df965faf0e489e17a7e0b0ccf36c8bf84"
   },
   "outputs": [],
   "source": [
    "# 绘制Confusion Matrix和计算分类指标\n",
    "def plot_confusion_matrix(\n",
    "        cm, classes, y_pred, y,\n",
    "        title='Confusion matrix',\n",
    "        cmap=plt.cm.Blues,\n",
    "        plot_flag=True\n",
    "    ):\n",
    "    \n",
    "    # 计算AUC\n",
    "    test_fpr, test_tpr, te_thresholds = metrics.roc_curve(y, y_pred)\n",
    "    auc = metrics.auc(test_fpr, test_tpr)\n",
    "    \n",
    "    if plot_flag:\n",
    "        # 绘制confusion matrix\n",
    "        fmt = 'd' \n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt), fontsize=20,\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title, fontsize=20)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, fontsize=15)\n",
    "        plt.yticks(tick_marks, classes, fontsize=15)\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label', fontsize=20)\n",
    "        plt.xlabel('Predicted label', fontsize=20)\n",
    "\n",
    "        # 绘制AUC curve\n",
    "        fig, ax = plt.subplots(figsize=(6,5))\n",
    "        plt.grid()\n",
    "        plt.plot(test_fpr, test_tpr, label=f\"AUC={auc:.4f}\")\n",
    "        plt.plot([0,1],[0,1],'g--')\n",
    "        plt.legend(fontsize=20)\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.xlabel(\"False Positive Rate\", fontsize=20)\n",
    "        plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "        plt.title(\"AUC (ROC curve)\", fontsize=20)\n",
    "        plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Accuracy: {metrics.accuracy_score(y, y_pred):.4f}, Precision: {metrics.precision_score(y, y_pred):.4f}, Recall: {metrics.recall_score(y, y_pred):.4f}, F1 score: {metrics.f1_score(y, y_pred):.4f}\")\n",
    "        \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察不平衡的数据会导致什么问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "32763345-e2ac-455b-9265-50bcc304da07",
    "_uuid": "5139011572ad26820d148f408fb3d839899331b5"
   },
   "outputs": [],
   "source": [
    "# 为了加速，只取前10000个数据实例用于训练\n",
    "df_demo_train = df[0:10000]\n",
    "# 在用于训练的特征数据中，我们抛弃无用的时间特征Time。把交易类别Class作为目标分类标签\n",
    "X_demo_train = df_demo_train.drop(['Time', 'Class'],axis=1)\n",
    "y_demo_train = df_demo_train['Class']\n",
    "X_demo_train = np.asarray(X_demo_train)\n",
    "y_demo_train = np.asarray(y_demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000以后的数据实例都用于测试\n",
    "df_demo_test_all = df[10000:]\n",
    "X_demo_test_all = df_demo_test_all.drop(['Time', 'Class'],axis=1)\n",
    "y_demo_test_all = df_demo_test_all['Class']\n",
    "X_demo_test_all = np.asarray(X_demo_test_all)\n",
    "y_demo_test_all = np.asarray(y_demo_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 用默认参数的SVM分类模型\n",
    "classifier_demo = svm.SVC()\n",
    "classifier_demo.fit(X_demo_train, y_demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 预测标签，画出性能评估结果\n",
    "prediction_SVM_demo = classifier_demo.predict(X_demo_test_all)\n",
    "cm = metrics.confusion_matrix(y_demo_test_all, prediction_SVM_demo)\n",
    "plot_confusion_matrix(cm,class_names, prediction_SVM_demo, y_demo_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "527f2804-0aa7-4220-aa9b-03f6b8c0a9fe",
    "_uuid": "8a4df6becaba62481d52118f944612c8c579b8e7"
   },
   "source": [
    "**样本不平衡解决方法:**\n",
    "- 过采样（oversampling），增加正样本，使得正、负样本数目接近，然后再进行学习。\n",
    "- 欠采样（undersampling），去除一些负样本，使得正、负样本数目接近，然后再进行学习\n",
    "\n",
    "由于我们没有足够的数据去增加正样本，这里我们使用欠采样方法平衡样本。注意：只有当我们能够确保所选的少数样本（在这种情况下是非欺诈交易）能够代表整个数据集中所有非欺诈交易时，我们才能使用欠采样方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "679f5dd1-5665-4de2-942b-6ac95ff1a02f",
    "_uuid": "d5b23951407345e6a89ca312967e582c66e11af3"
   },
   "outputs": [],
   "source": [
    "# 类似的，我们将全部数据划分为训练集和测试集\n",
    "# 训练集从前15万个数据实例中构造\n",
    "df_train_all = df[0:150000]\n",
    "# 根据标签筛选这15万个交易记录中的欺诈交易和非欺诈交易\n",
    "df_train_1 = df_train_all[df_train_all['Class'] == 1]\n",
    "df_train_0 = df_train_all[df_train_all['Class'] == 0]\n",
    "print('In this partial dataset, we have ' + str(len(df_train_1)) +\" fraud cases, so we need to sample a similar number of non-fraud cases\")\n",
    "\n",
    "# 通常来说，应该随机采样负样本（df_sample=df_train_0.sample(300)），这里为了避免随机性影响结果，只取前300个负样本\n",
    "df_sample=df_train_0[0:300]\n",
    "df_train = pd.concat([df_train_1, df_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "36f77663-2b2a-412f-a759-0fd3a0bf06ab",
    "_uuid": "d9707da7dc04b2a415608f2833dd5d732dd98925"
   },
   "outputs": [],
   "source": [
    "# 在用于训练的特征数据中，我们抛弃无用的时间特征Time。把交易类别Class作为目标分类标签\n",
    "X_train = df_train.drop(['Time', 'Class'],axis=1)\n",
    "y_train = df_train['Class']\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d7c350a4-6874-46b8-b699-4c27aa42dade",
    "_uuid": "975a023dc24a60832b3a670aecf2dbe3b9390183"
   },
   "outputs": [],
   "source": [
    "# 前15万个样本之后的数据实例全部用于测试\n",
    "df_test_all = df[150000:]\n",
    "X_test_all = df_test_all.drop(['Time', 'Class'],axis=1)\n",
    "y_test_all = df_test_all['Class']\n",
    "X_test_all = np.asarray(X_test_all)\n",
    "y_test_all = np.asarray(y_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1：用欠采样调整训练集后，观察模型性能有何变化。注意：为公平比较，仍然采用默认参数的SVM分类模型。（50%）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_default = svm.SVC()\n",
    "# 填入正确的代码，训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_SVM = classifier_default.predict(X_test_all)\n",
    "cm = metrics.confusion_matrix(y_test_all, prediction_SVM)\n",
    "plot_confusion_matrix(cm,class_names, prediction_SVM, y_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "934444aa-0a22-4b60-b363-c4af3ab8ffe9",
    "_uuid": "ce9fa83195b843375a102593ee1ece0b9efdad97"
   },
   "source": [
    "# 特征重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a575fa45-aa54-42d8-bc41-7901109b0a30",
    "_uuid": "c79fd2aee5021d4f09523411513e43220bede053"
   },
   "outputs": [],
   "source": [
    "# 计算每一对特征之间的皮尔森相关系数\n",
    "df_corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f3fbb40b-c628-45bc-96df-599c83ea1a7f",
    "_uuid": "238eb36a153c7049fef3fd5f4f07f363b4aa92b9"
   },
   "outputs": [],
   "source": [
    "# 画出相关系数的热力图\n",
    "plt.figure(figsize=(6,5))\n",
    "seaborn.heatmap(df_corr, cmap='Blues') \n",
    "seaborn.set(font_scale=2,style='white')\n",
    "\n",
    "plt.title('Heatmap correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以注意到的，大多数特征之间没有相关性。这证实了数据说明中关于这些特征来源的解释：由于保密原因，数据无法提供交易方的原始特征和更多关于数据的背景信息。除开'Time'和'Amount'，其他特征都是通过主成分分析（Principle Component Aanalysis）获得的主成分。\n",
    "\n",
    "即便如此，这31个特征，每一个特征对提升模型性能都一样有效吗？由于我们关心特征是否有助于我们更加正确地预测交易类型，我们以特征和Class的相关性为标准，来观察不同的特征对模型性能贡献的区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "513071fd-e5e9-4ad5-a45a-bfcfa9376cdc",
    "_uuid": "f5b17abf4e8a26f4f63f4379b1d0b2822b5a3c85"
   },
   "outputs": [],
   "source": [
    "# 获取每个特征和Class特征的相关系数，并将其按照绝对值降序排序\n",
    "rank = df_corr['Class']\n",
    "df_rank = pd.DataFrame(rank) \n",
    "df_rank = np.abs(df_rank).sort_values(by='Class',ascending=False)\n",
    "df_rank.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0b4284ab-89fc-4992-919b-b2fce118c601",
    "_uuid": "6506e5ce2aaa631f98c3290a6a35bd2cdc16a62d"
   },
   "source": [
    "只用相关性绝对值排名靠前的k个特征，重新训练和评估模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d7246290-1ada-4be9-87a3-833620d23e04",
    "_uuid": "274f5e99f592cdc487e39eb60419a17a1cada5fe"
   },
   "outputs": [],
   "source": [
    "k = 2\n",
    "X_train_rank = df_train[df_rank.index[1:k]]\n",
    "X_train_rank = np.asarray(X_train_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1c9addbe-d94c-44e8-84a9-1afdd13291be",
    "_uuid": "7a28465f8d7a4577ca6f4d1eb1f372a87da87c63"
   },
   "outputs": [],
   "source": [
    "# 测试数据也相应的只用挑选的k个特征的数据实例\n",
    "X_test_all_rank = df_test_all[df_rank.index[1:k]]\n",
    "X_test_all_rank = np.asarray(X_test_all_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_feature = svm.SVC()\n",
    "classifier_feature.fit(X_train_rank, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_SVM_feature = classifier_feature.predict(X_test_all_rank)\n",
    "cm = metrics.confusion_matrix(y_test_all, prediction_SVM_feature)\n",
    "plot_confusion_matrix(cm,class_names, prediction_SVM_feature, y_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2：模仿“第二章-线性模型”课件的第71页，找出最优的特征（50%）\n",
    "<div>\n",
    "<img src=\"./slides.jpg\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findK():\n",
    "    auc = []\n",
    "    # 填入正确的代码\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auc = findK()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.grid()\n",
    "plt.plot(range(0,len(auc)), auc)\n",
    "plt.xlabel(\"Number of features\", fontsize=20)\n",
    "plt.ylabel(\"AUC\", fontsize=20)\n",
    "plt.title(\"SVM classification results\", fontsize=20)\n",
    "plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "66ca64cd-078d-4a1c-8ecd-d85a247ef5f3",
    "_uuid": "a38206000a28bcc2baf07d0d8e10f7eb1256f993"
   },
   "source": [
    "# 类型标签权重优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10579138-58f9-41db-b5a7-25f6c4741900",
    "_uuid": "6cd3881e06f80ba87e4377c525572db1585e1c84"
   },
   "source": [
    "在这之前使用的支持向量机（SVM）模型中，每个类别的权重是相同的，这意味着漏检一个欺诈交易与误判一个非欺诈交易一样严重。然而，对于银行来说，它们的目标是尽可能准确地检测到欺诈交易！\n",
    "\n",
    "实际上，通过修改SVM模型中的```class_weight```参数，我们可以在模型训练阶段选择给哪个类别更多的重视。在本例中，描述欺诈交易的```class_1```事件的权重应该比描述非欺诈交易的```class_0```事件的权重更大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_weighted = svm.SVC(class_weight={0:0.3, 1:0.7})\n",
    "classifier_weighted.fit(X_train_rank, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_SVM_weighted = classifier_weighted.predict(X_test_all_rank)\n",
    "cm = metrics.confusion_matrix(y_test_all, prediction_SVM_weighted)\n",
    "auc_weighted = plot_confusion_matrix(cm,class_names, prediction_SVM_weighted, y_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f7de7e6f-e51d-4e83-9d4e-6b0abdd2c726",
    "_uuid": "95ccdb3d1da9c590cb7b984f7f7a3151c316509c"
   },
   "source": [
    "# Q3：模型超参数调优（加分题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "08c5814b-f154-476b-a91b-09682911a7fc",
    "_uuid": "940007266bccc4c732bfe0d990e7307eddb53293",
    "scrolled": true
   },
   "source": [
    "通过筛选特征、改变类别标签权重、改变核函数、改变正则化项权重等等超参数调优方法进一步提高模型性能。具体的设置可以参考SVM的相关超参数[说明](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)、scikit-learn中基于交叉验证的超参数调优函数[```GridSearchCV```](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)、网络资源、大语言模型等等。\n",
    "\n",
    "注意事项：\n",
    "- 不能修改```plot_confusion_matrix```函数；\n",
    "- 不能修改```y_test_all```；\n",
    "- 训练集只能从前15万个数据实例中构造，前15万个样本之后的数据实例全部用于测试；\n",
    "- 加分计算方法：当你得到的最优AUC（记作$x^{*}$）大于调整类型标签权重后得到的AUC（记作$x^{\\text{weighted}}$，即```auc_weighted=0.8357```）时，你能得到的加分为$p=\\lceil\\min\\{(x^{*}-x^{\\text{weighted}})\\times 100, 10\\}\\rceil$，其中$\\lceil\\cdot\\rceil$为向上取整函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可能可以参考的超参数搜索函数\n",
    "def model_selection(X, y):    \n",
    "    param_set = [\n",
    "        {\n",
    "            'kernel': ['linear'], \n",
    "            'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], # [ 2**j for j in range(-10,10) ], \n",
    "            'class_weight': [{1:i/100.0, 0:(100-i)/100.0} for i in range(20,100,10)]\n",
    "        },\n",
    "    ]\n",
    "    clf = GridSearchCV(svm.SVC(), param_set, n_jobs = 15, cv = 3)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    return clf\n",
    "\n",
    "clf = model_selection(X_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现你的超参数调优方案\n",
    "\n",
    "prediction_yours = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出你的预测结果\n",
    "cm = metrics.confusion_matrix(y_test_all, prediction_yours)\n",
    "auc_yours = plot_confusion_matrix(cm,class_names, prediction_yours, y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你的附加分\n",
    "auc_weighted=0.8357\n",
    "p=math.ceil(min((auc_yours-auc_weighted)*100,10))\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
