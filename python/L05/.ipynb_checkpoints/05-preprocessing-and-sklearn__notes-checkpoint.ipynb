{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 451: Machine Learning (Fall 2020)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat451-fs2020/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L05 - Data Preprocessing and Machine Learning with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.8.3\n",
      "IPython 7.18.1\n",
      "\n",
      "numpy 1.19.1\n",
      "scipy 1.5.0\n",
      "matplotlib 3.3.1\n",
      "sklearn 0.23.2\n",
      "mlxtend 0.17.3\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -a 'Sebastian Raschka' -p numpy,scipy,matplotlib,sklearn,mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we are closing the \"Computational Foundation\" section by introducing yet another Python library, pandas, which is extremely handy for data (pre)processing. The second focus of this lecture is on the [Scikit-learn](http://scikit-learn.org) machine learning library, which is widely considered as the most mature and most well-designed general machine learning library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas -- A Python Library for Working with Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas is probably the most popular and convenient data wrangling library for Python (official website: https://pandas.pydata.org) \n",
    "- Pandas stands for PANel-DAta-S.\n",
    "- Relativ similar to data frames in R.\n",
    "- How is it different from NumPy arrays? \n",
    "    - Allows for heterogenous data (columns can have different data types)\n",
    "    - Adds some more convenient functions on top that are handy for data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Tabular Datasets from Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, we are working with structured data, data which is organized similar to a \"design matrix\" (see lecture 1) -- that is, examples as rows and features as columns (in contrast: unstructured data such as text or images, etc.).\n",
    "- CSV stands for \"comma separated values\" (also common: TSV, tab seperated values).\n",
    "- The `head` command is a Linux/Unix command that shows the first 10 rows by default; the `!` denotes that Jupyter/the IPython kernel should execute it as a shell command (`!`-commands may not work if you are on Windows, but it is not really important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!head data/iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use the `read_csv` command to load the CSV file into a pandas data frame object f of the class `DataFrame`.\n",
    "- Data frames also have a `head` command; here it shows the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLength[cm]</th>\n",
       "      <th>SepalWidth[cm]</th>\n",
       "      <th>PetalLength[cm]</th>\n",
       "      <th>PetalWidth[cm]</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLength[cm]  SepalWidth[cm]  PetalLength[cm]  PetalWidth[cm]  \\\n",
       "0   1              5.1             3.5              1.4             0.2   \n",
       "1   2              4.9             3.0              1.4             0.2   \n",
       "2   3              4.7             3.2              1.3             0.2   \n",
       "3   4              4.6             3.1              1.5             0.2   \n",
       "4   5              5.0             3.6              1.4             0.2   \n",
       "\n",
       "       Species  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is always good to double check the dimensions and see if they are what we expect. \n",
    "- The `DataFrame` `shape` attribute works the same way as the NumPy array `shape` attribute (Lecture 04)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `apply` method offers a convenient way to manipulate pandas `DataFrame` entries along the column axis.\n",
    "- We can use a regular Python or lambda function as input to the apply method.\n",
    "- In this context, assume that our goal is to transform class labels from a string representation (e.g., \"Iris-Setosa\") to an integer representation (e.g., 0), which is a historical convention and a recommendation for compatibility with various machine learning tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLength[cm]</th>\n",
       "      <th>SepalWidth[cm]</th>\n",
       "      <th>PetalLength[cm]</th>\n",
       "      <th>PetalWidth[cm]</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLength[cm]  SepalWidth[cm]  PetalLength[cm]  PetalWidth[cm]  \\\n",
       "0   1              5.1             3.5              1.4             0.2   \n",
       "1   2              4.9             3.0              1.4             0.2   \n",
       "2   3              4.7             3.2              1.3             0.2   \n",
       "3   4              4.6             3.1              1.5             0.2   \n",
       "4   5              5.0             3.6              1.4             0.2   \n",
       "\n",
       "  Species  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Species'] = df['Species'].apply(lambda x: 0 if x=='Iris-setosa' else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digression: Lambda Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you are not familiar with \"lambda functions,\" they are basically the same as \"regular function but can be written more compactly as a one-liner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World 123'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def some_func(x):\n",
    "    return 'Hello World ' + str(x)\n",
    "\n",
    "some_func(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World 123'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: 'Hello World ' + str(x)\n",
    "f(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .map vs. .apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we want to map column values from one value to another, it is often more convenient to use the `map` method instead of apply.\n",
    "- The achieve the following with the `apply` method, we would have to call `apply` three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLength[cm]</th>\n",
       "      <th>SepalWidth[cm]</th>\n",
       "      <th>PetalLength[cm]</th>\n",
       "      <th>PetalWidth[cm]</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLength[cm]  SepalWidth[cm]  PetalLength[cm]  PetalWidth[cm]  \\\n",
       "0   1              5.1             3.5              1.4             0.2   \n",
       "1   2              4.9             3.0              1.4             0.2   \n",
       "2   3              4.7             3.2              1.3             0.2   \n",
       "3   4              4.6             3.1              1.5             0.2   \n",
       "4   5              5.0             3.6              1.4             0.2   \n",
       "\n",
       "   Species  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Iris-setosa': 0,\n",
    "     'Iris-versicolor': 1,\n",
    "     'Iris-virginica': 2}\n",
    "\n",
    "df = pd.read_csv('data/iris.csv')\n",
    "df['Species'] = df['Species'].map(d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `tail` method is similar to `head` but shows the last five rows by default; we use it to double check that the last class label  (Iris-Virginica) was also successfully transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLength[cm]</th>\n",
       "      <th>SepalWidth[cm]</th>\n",
       "      <th>PetalLength[cm]</th>\n",
       "      <th>PetalWidth[cm]</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLength[cm]  SepalWidth[cm]  PetalLength[cm]  PetalWidth[cm]  \\\n",
       "145  146              6.7             3.0              5.2             2.3   \n",
       "146  147              6.3             2.5              5.0             1.9   \n",
       "147  148              6.5             3.0              5.2             2.0   \n",
       "148  149              6.2             3.4              5.4             2.3   \n",
       "149  150              5.9             3.0              5.1             1.8   \n",
       "\n",
       "     Species  \n",
       "145        2  \n",
       "146        2  \n",
       "147        2  \n",
       "148        2  \n",
       "149        2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's actually not a bad idea to check if all row entries of the `Species` column got transformed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "np.unique(df['Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas' data frames are built on top of NumPy arrays.\n",
    "- While many machine learning-related tools also support pandas `DataFrame` objects as inputs now, by convention, we usually use NumPy arrays most tasks.\n",
    "- We can access the NumPy array that is underlying a `DataFrame` via the `values` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Species'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are many different ways to access columns and rows in a pandas `DataFrame`, which we won't discuss here; a good reference documentation can be found at https://pandas.pydata.org/pandas-docs/stable/indexing.html\n",
    "- The `iloc` attribute allows for integer-based indexing and slicing, which is similar to how we use indexing on NumPy arrays (Lecture 04).\n",
    "The following expression will select column 1, 2, 3, and 4 (sepal length, sepal width, petal length, petal width) from the `DataFrame` and then assign the underlying NumPy array to `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:5].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just as a quick check, we show the first 5 rows in the NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Occasionally, we will use the MLxtend library (http://rasbt.github.io/mlxtend/) -- MLxtend stands for \"machine learning extensions\" and contains some convenience functions for machine learning and data science tasks.\n",
    "- In particular, we will use the `scatterplotmatrix` function to display a scatter plot matrix of the dataset, which is useful to get a quick overview of the dataset (to inspect the relationship between features, look for outliers, etc.).\n",
    "- I just added the `scatterplotmatrix` functions a few days ago, hence it is not in mlxtend's latest release version; however, you can install the development version (currently 0.14dev) directly from GitHub by un-commenting and executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install mlxtend --channel conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iris_data\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scatterplotmatrix\n\u001b[0;32m      7\u001b[0m names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.data import iris_data\n",
    "from mlxtend.plotting import scatterplotmatrix\n",
    "\n",
    "\n",
    "names = df.columns[1:5]\n",
    "\n",
    "fig, axes = scatterplotmatrix(X[y==0], figsize=(10, 8), alpha=0.5)\n",
    "fig, axes = scatterplotmatrix(X[y==1], fig_axes=(fig, axes), alpha=0.5)\n",
    "fig, axes = scatterplotmatrix(X[y==2], fig_axes=(fig, axes), alpha=0.5, names=names)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(labels=['Setosa', 'Versicolor', 'Virginica'])\n",
    "plt.savefig('images/eda.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.2-py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Collecting scikit-learn>=1.3.1\n",
      "  Downloading scikit_learn-1.5.2-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\yan\\appdata\\roaming\\python\\python39\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (3.5.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Collecting joblib>=0.13.2\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting numpy>=1.16.2\n",
      "  Downloading numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Installing collected packages: numpy, threadpoolctl, joblib, scikit-learn, mlxtend\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\Yan\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Yan\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\~-mpy.libs\\\\libopenblas64__v0.3.23-293-gc2f4bdbb-gcc_10_3_0-2bde3a66a51006b2b53eb373ff767a3f.dll'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting a Dataset into Train, Validation, and Test Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following code cells in this section illustrate the process of splitting a dataset into several subsets.\n",
    "- One important step, prior to splitting a dataset, is shuffling it, otherwise, we may end up with unrepresentative class distributions if the dataset was sorted prior to splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72, 112, 132,  88,  37, 138,  87,  42,   8,  90, 141,  33,  59,\n",
       "       116, 135, 104,  36,  13,  63,  45,  28, 133,  24, 127,  46,  20,\n",
       "        31, 121, 117,   4, 130, 119,  29,   0,  62,  93, 131,   5,  16,\n",
       "        82,  60,  35, 143, 145, 142, 114, 136,  53,  19,  38, 110,  23,\n",
       "         9,  86,  91,  89,  79, 101,  65, 115,  41, 124,  95,  21,  11,\n",
       "       103,  74, 122, 118,  44,  51,  81, 149,  12, 129,  56,  50,  25,\n",
       "       128, 146,  43,   1,  71,  54, 100,  14,   6,  80,  26,  70, 139,\n",
       "        30, 108,  15,  18,  77,  22,  10,  58, 107,  75,  64,  69,   3,\n",
       "        40,  76, 134,  34,  27,  94,  85,  97, 102,  52,  92,  99, 105,\n",
       "         7,  48,  61, 120, 137, 125, 147,  39,  84,   2,  67,  55,  49,\n",
       "        68, 140,  78, 144, 111,  32,  73,  47, 148, 113,  96,  57, 123,\n",
       "       106,  83,  17,  98,  66, 126, 109])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "rng = np.random.RandomState(123)\n",
    "permuted_indices = rng.permutation(indices)\n",
    "permuted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 22 31\n"
     ]
    }
   ],
   "source": [
    "train_size, valid_size = int(0.65*X.shape[0]), int(0.15*X.shape[0])\n",
    "test_size = X.shape[0] - (train_size + valid_size)\n",
    "print(train_size, valid_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = permuted_indices[:train_size]\n",
    "valid_ind = permuted_indices[train_size:(train_size + valid_size)]\n",
    "test_ind = permuted_indices[(train_size + valid_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = X[train_ind], y[train_ind]\n",
    "X_valid, y_valid = X[valid_ind], y[valid_ind]\n",
    "X_test, y_test = X[test_ind], y[test_ind]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This section illustrates the concept of \"classes\" in Python, which is relevant for understanding how the scikit-learn API works on a fundamental level later in this lecture.\n",
    "- Note that Python is an object oriented language, and everything in Python is an object.\n",
    "- Classes are \"templates\" for creating objects (this is called \"instantiating\" objects).\n",
    "- An object is a collection of special \"functions\" (a \"function\" of an object or class is called \"method\") and attributes.\n",
    "- Note that the `self` attribute is a special keyword for referring to a class or an instantiated object of a class, \"itself.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehicleClass():\n",
    "    \n",
    "    def __init__(self, horsepower):\n",
    "        \"This is the 'init' method\"\n",
    "        # this is a class attribute:\n",
    "        self.horsepower = horsepower\n",
    "        \n",
    "    def horsepower_to_torque(self, rpm):\n",
    "        \"This is a regular method\"\n",
    "        numerator = self.horsepower * 33000\n",
    "        denominator = 2* np.pi * 5000\n",
    "        return numerator/denominator\n",
    "    \n",
    "    def tune_motor(self):\n",
    "        self.horsepower *= 2\n",
    "    \n",
    "    def _private_method(self):\n",
    "        print('this is private')\n",
    "    \n",
    "    def __very_private_method(self):\n",
    "        print('this is very private')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "# instantiate an object:\n",
    "car1 = VehicleClass(horsepower=123)\n",
    "print(car1.horsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129.20198280200063"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car1.horsepower_to_torque(rpm=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258.40396560400126"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car1.tune_motor()\n",
    "car1.horsepower_to_torque(rpm=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is private\n"
     ]
    }
   ],
   "source": [
    "car1._private_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python has the motto \"we are all adults here,\" which means that a user can do the same things as a developer (in contrast to other programming languages, e.g., Java).\n",
    "- A preceding underscore is an indicator that a method is considered \"private\" -- this means, this method is meant to be used internally but not by the user directly (also, it does not show up in the \"help\" documentation)\n",
    "- a preceding double-underscore is a \"stronger\" indicator for methods that are supposed to be private, and while users can access these (adhering to the \"we are all adults here\" moto), we have to refer to \"name mangling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excecuting the following would raise an error:\n",
    "# car1.__very_private_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is very private\n"
     ]
    }
   ],
   "source": [
    "# If we use \"name mangling\" we can access this private method:\n",
    "car1._VehicleClass__very_private_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another useful aspect of using classes is the concept of \"inheritance.\"\n",
    "- Using inheritance, we can \"inherit\" methods and attributes from a parent class for re-use.\n",
    "- For instance, consider the `VehicleClass` as a more general class than the `CarClass` -- i.e., a car, truck, or motorbike are specific cases of a vehicle.\n",
    "- Below is an example of a `CarClass` that inherits the methods from the `VehicleClass` and adds a specific `self.num_wheels=4` attribute -- if we were to create a `BikeClass`, we could set this to `self.num_wheels=2`, for example.\n",
    "- All-in-all, this is a very simple demonstration of class inheritance, however, it's a concept that is very useful for writing \"clean code\" and structuring projects -- the scikit-learn machine learning library makes heavy use of this concept internally (we, as users, don't have to worry about it too much though, it is useful to know though in case you would like to modify or contribute to the library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wheels: 4\n",
      "Horsepower: 123\n",
      "Horsepower: 246\n"
     ]
    }
   ],
   "source": [
    "class CarClass(VehicleClass):\n",
    "\n",
    "    def __init__(self, horsepower):\n",
    "        super(CarClass, self).__init__(horsepower)\n",
    "        self.num_wheels = 4\n",
    "    \n",
    "new_car = CarClass(horsepower=123)\n",
    "print('Number of wheels:', new_car.num_wheels)\n",
    "print('Horsepower:', new_car.horsepower)\n",
    "new_car.tune_motor()\n",
    "print('Horsepower:', new_car.horsepower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below is a very simple implementation of a K-nearest Neighbor classifier.\n",
    "- This is a very slow and inefficient implementation, and in real-world problems, it is always recommended to use established libraries (like scikit-learn) instead of implementing algorithms from scratch.\n",
    "- The scikit-learn library, for example, implements *k*NN much more efficiently and robustly -- using advanced data structures (KD-Tree and Ball-Tree, which we briefly discussed in Lecture 02).\n",
    "- A scenario where it is useful to implement algorithms from scratch is for learning and teaching purposes, or if we want to try out new algorithms, hence, the implementation below, which gently introduces how things are implemented in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier(object):\n",
    "    def __init__(self, k, dist_fn=None):\n",
    "        self.k = k\n",
    "        if dist_fn is None:\n",
    "            self.dist_fn = self._euclidean_dist\n",
    "    \n",
    "    def _euclidean_dist(self, a, b):\n",
    "        dist = 0.\n",
    "        for ele_i, ele_j in zip(a, b):\n",
    "            dist += ((ele_i - ele_j)**2)\n",
    "        dist = dist**0.5\n",
    "        return dist\n",
    "        \n",
    "    def _find_nearest(self, x):\n",
    "        dist_idx_pairs = []\n",
    "        for j in range(self.dataset_.shape[0]):\n",
    "            d = self.dist_fn(x, self.dataset_[j])\n",
    "            dist_idx_pairs.append((d, j))\n",
    "            \n",
    "        sorted_dist_idx_pairs = sorted(dist_idx_pairs)\n",
    "\n",
    "        return sorted_dist_idx_pairs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.dataset_ = X.copy()\n",
    "        self.labels_ = y.copy()\n",
    "        self.possible_labels_ = np.unique(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(X.shape[0], dtype=int)\n",
    "        for i in range(X.shape[0]):\n",
    "            k_nearest = self._find_nearest(X[i])[:self.k]\n",
    "            indices = [entry[1] for entry in k_nearest]\n",
    "            k_labels = self.labels_[indices]\n",
    "            counts = np.bincount(k_labels,\n",
    "                                 minlength=self.possible_labels_.shape[0])\n",
    "            pred_label = np.argmax(counts)\n",
    "            predictions[i] = pred_label\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "\n",
    "knn_model = KNNClassifier(k=3)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 1 1 1 0 0 1 2 0 0 1 1 1 2 1 1 1 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(knn_model.predict(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are class attributes with a `_` suffix in the implementation above -- this is not a typo.\n",
    "- The trailing `_` (e.g., here: `self.dataset_`) is a scikit-learn convention and indicates that these are \"fit\" attributes -- that is, attributes that are available only *after* calling the `fit` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Scikit-Learn Estimator API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below is an overview of the scikit-learn estimator API, which is used for implementing classification and regression models/algorithms.\n",
    "- We have seen the methods in the context of the *k*NN implementation earlier; however, one interesting, additional method we have not covered yet is `score`.\n",
    "- The `score` method simply runs `predict` on the features (`X`) internally and then computes the performance by comparing the predicted targets to the true targets `y`.\n",
    "- In the case of classification models, the `score` method computes the classification accuracy (in the range [0, 1]) -- i.e., the proportion of correctly predicted labels.\n",
    "In the case of regression models, the `score` method computes the coefficient of determination ($R^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class SupervisedEstimator(...):\n",
    "    \n",
    "    def __init__(self, hyperparam_1, ...):\n",
    "        self.hyperparm_1\n",
    "        ...\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        ...\n",
    "        self.fit_attribute_\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ...\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        ...\n",
    "        return score\n",
    "    \n",
    "    def _private_method(self):\n",
    "        ...\n",
    "    ...\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The graphic below summarizes the useage of the `SupervisedEstimator` API that scikit-learn uses for implementing classification and regression algorithms/models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/estimator-api.png\" alt=\"drawing\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For 2D datasets (which we usually only have in teaching/learning contexts), we can plot the decision regions using a convenient wrapper function in  mlxtend as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train[:, 2:], y_train)\n",
    "plot_decision_regions(X_train[:, 2:], y_train, knn_model)\n",
    "plt.xlabel('petal length[cm]')\n",
    "plt.ylabel('petal width[cm]')\n",
    "plt.savefig('images/decisionreg.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Previously, we wrote our own code to shuffle and split a dataset into training, validation, and test subsets, which had one considerable downside.\n",
    "- If we are working with small datasets and split it randomly into subsets, it will affect the class distribution in the samples -- this is problematic since machine learning algorithms/models assume that training, validation, and test samples have been drawn from the same distributions to produce reliable models and estimates of the generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/iris-subsampling.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The method of ensuring that the class label proportions are the same in each subset after splitting, we use an approach that is usually referred to as \"stratification.\"\n",
    "- Stratification is supported in scikit-learn's `train_test_split` method if we pass the class label array to the `stratify` parameter as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 40, 40])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = \\\n",
    "        train_test_split(X, y, test_size=0.2, \n",
    "                         shuffle=True, random_state=123, stratify=y)\n",
    "np.bincount(y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size (96, 4) class proportions [32 32 32]\n",
      "Valid size (24, 4) class proportions [8 8 8]\n",
      "Test size (30, 4) class proportions [10 10 10]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X_temp, y_temp, test_size=0.2,\n",
    "                         shuffle=True, random_state=123, stratify=y_temp)\n",
    "\n",
    "print('Train size', X_train.shape, 'class proportions', np.bincount(y_train))\n",
    "print('Valid size', X_valid.shape, 'class proportions', np.bincount(y_valid))\n",
    "print('Test size', X_test.shape, 'class proportions', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the case of the Iris dataset, all dimensions were measured in centimeters, hence \"scaling\" features would not be necessary in the context of *k*NN -- unless we want to weight features differently.\n",
    "- Whether or not to scale features depends on the problem at hand and requires your judgement.\n",
    "- However, there are several algorithms (especially gradient-descent, etc., which we will cover later in this course), which work much better (are more robust, numerically stable, and converge faster) if the data is centered and has a smaller range.\n",
    "- There are many different ways for scaling features; here, we only cover to of the most common \"normalization\" schemes: min-max scaling and z-score standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization -- Min-max scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Min-max scaling squashes the features into a [0, 1] range, which can be achieved via the following equation for a single input $i$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^{[i]}_{\\text{norm}} = \\frac{x^{[i]} - x_{\\text{min}} }{ x_{\\text{max}} - x_{\\text{min}} }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below is an example of how we can implement and apply min-max scaling on 6 data instances given a 1D input vector (1 feature) via NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(6).astype(float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm = (x - x.min()) / (x.max() - x.min())\n",
    "x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Z-score standardization is a useful standardization scheme if we are working with certain optimization methods (e.g., gradient descent, later in this course). \n",
    "- After standardizing a feature, it will have the properties of a standard normal distribution, that is, unit variance and zero mean ($N(\\mu=0, \\sigma^2=1)$); however, this does not transform a feature from not following a normal distribution to a normal distributed one.\n",
    "- The formula for standardizing a feature is shown below, for a single data point $x^{[i]}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^{[i]}_{\\text{std}} = \\frac{x^{[i]} - \\mu_x }{ \\sigma_{x} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(6).astype(float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.46385011, -0.87831007, -0.29277002,  0.29277002,  0.87831007,\n",
       "        1.46385011])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std = (x - x.mean()) / x.std()\n",
    "x_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conveniently, NumPy and Pandas both implement a `std` method, which computes the standard devation.\n",
    "- Note the different results shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1690451944500122"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([1, 2, 1, 2, 3, 4])\n",
    "df[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0671873729054748"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].values.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The results differ because Pandas computes the \"sample\" standard deviation ($s_x$), whereas NumPy computes the \"population\" standard deviation ($\\sigma_x$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$s_x = \\sqrt{ \\frac{1}{n-1} \\sum^{n}_{i=1} (x^{[i]} - \\bar{x})^2 }$$\n",
    "\n",
    "$$\\sigma_x = \\sqrt{ \\frac{1}{n} \\sum^{n}_{i=1} (x^{[i]} - \\mu_x)^2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the context of machine learning, since we are typically working with large datasets, we typically don't care about Bessel's correction (subtracting one degree of freedom in the denominator).\n",
    "- Further, the goal here is not to model a particular distribution or estimate distribution parameters accurately; however, if you like, you can remove the extra degree of freedom via NumPy's `ddof` parameters -- it's not necessary in practice though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1690451944500122"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].values.std(ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A concept that is very important though is how we use the estimated normalization parameters (e.g., mean and standard deviation in z-score standardization).\n",
    "- In particular, it is important that we re-use the parameters estimated from the training set to transfrom validation and test sets -- re-estimating the parameters is a common \"beginner-mistake\" which is why we discuss it in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "\n",
    "X_train_std = (X_train - mu) / sigma\n",
    "X_valid_std = (X_valid - mu) / sigma\n",
    "X_test_std = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Again, if we standardize the training dataset, we need to keep the parameters (mean and standard deviation for each feature). Then, we’d use these parameters to transform our test data and any future data later on\n",
    "- Let’s assume we have a simple training set consisting of 3 samples with 1 feature column (let’s call the feature column “length in cm”):\n",
    "\n",
    "- example1: 10 cm -> class 2\n",
    "- example2: 20 cm -> class 2\n",
    "- example3: 30 cm -> class 1\n",
    "\n",
    "Given the data above, we estimate the following parameters from this training set:\n",
    "\n",
    "- mean: 20\n",
    "- standard deviation: 8.2\n",
    "\n",
    "If we use these parameters to standardize the same dataset, we get the following z-score values:\n",
    "\n",
    "- example1: -1.21 -> class 2\n",
    "- example2: 0 -> class 2\n",
    "- example3: 1.21 -> class 1\n",
    "\n",
    "Now, let’s say our model has learned the following hypotheses: It classifies samples with a standardized length value < 0.6 as class 2 (and class 1 otherwise). So far so good. Now, let’s imagine we have 3 new unlabeled data points that you want to classify.\n",
    "\n",
    "- example4: 5 cm -> class ?\n",
    "- example5: 6 cm -> class ?\n",
    "- example6: 7 cm -> class ?\n",
    "\n",
    "If we look at the non-standardized \"length in cm\" values in the training datast, it is intuitive to say that all of these examples (5, 6, and 7) are likely belonging to class 2  because they are smaller than anything in the training set. However, if we standardize these by re-computing the standard deviation and and mean from the new data, we will get similar values as before (i.e., properties of a standard normal distribtion) in the training set and our classifier would (probably incorrectly) assign the “class 2” label to the samples 4 and 5.\n",
    "\n",
    "- example5: -1.21 -> class 2\n",
    "- example6: 0 -> class 2\n",
    "- example7: 1.21 -> class 1\n",
    "\n",
    "However, if we use the parameters from the \"training set standardization,\" we will get the following standardized values\n",
    "\n",
    "- example5: -18.37\n",
    "- example6: -17.15\n",
    "- example7: -15.92\n",
    "\n",
    "Note that these values are more negative than the value of example1 in the original training set, which makes much more sense now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Transformer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The transformer API in scikit-learn is very similar to the estimator API; the main difference is that transformers are typically \"unsupervised,\" meaning, they don't make use of class labels or target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer-api.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Typical examples of transformers in scikit-learn are the `MinMaxScaler` and the `StandardScaler`, which can be used to perform min-max scaling and z-score standardization as discussed earlier.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_valid_std = scaler.transform(X_valid)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When we preprocess a dataset as input to a machine learning algorithm, we have to be careful how we treat categorical variables.\n",
    "- There are two broad categories of categorical variables: nominal (no order implied) and ordinal (order implied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XXL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class1\n",
       "1    red    L   13.5     class2\n",
       "2   blue  XXL   15.3     class1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/categoricaldata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the example above, 'size' would be an example of an ordinal variable; i.e., if the letters refer to T-shirt sizes, it would make sense to come up with an ordering like M < L < XXL.\n",
    "- Hence, we can assign increasing values to a ordinal values; however, the range and difference between categories depends on our domain knowledge and judgement.\n",
    "- To convert ordinal variables into a proper representation for numerical computations via machine learning algorithms, we can use the now familiar `map` method in Pandas, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     2   10.1     class1\n",
       "1    red     3   13.5     class2\n",
       "2   blue     5   15.3     class1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {'M': 2,\n",
    "                'L': 3,\n",
    "                'XXL': 5}\n",
    "\n",
    "df['size'] = df['size'].map(mapping_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Machine learning algorithms do not assume an ordering in the case of class labels.\n",
    "- Here, we can use the `LabelEncoder` from scikit-learn to convert class labels to integers as an alternative to using the `map` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price  classlabel\n",
       "0  green     2   10.1           0\n",
       "1    red     3   13.5           1\n",
       "2   blue     5   15.3           0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['classlabel'] = le.fit_transform(df['classlabel'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Representing nominal variables properly is a bit more tricky.\n",
    "- Since machine learning algorithms usually assume an order if a variable takes on integer values, we need to apply a \"trick\" here such that the algorithm would not make this assumption.\n",
    "- this \"trick\" is also called \"one-hot\" encoding -- we binarize a nominal variable, as shown below for the color variable (again, we do this because some ordering like orange < red < blue would not make sense in many applications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size  price  classlabel  color_blue  color_green  color_red\n",
       "0     2   10.1           0           0            1          0\n",
       "1     3   13.5           1           0            0          1\n",
       "2     5   15.3           0           1            0          0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that executing the code above produced 3 new variables for \"color,\" each of which takes on binary values.\n",
    "- However, there is some redundancy now (e.g., if we know the values for `color_green` and `color_red`, we automatically know the value for `color_blue`).\n",
    "- While collinearity may cause problems (i.e., the matrix inverse doesn't exist in e.g., the context of the closed-form of linear regression), again, in machine learning we typically would not care about it too much, because most algorithms can deal with collinearity (e.g., adding constraints like regularization penalties to regression models, which we learn via gradient-based optimization).\n",
    "- However, removing collinearity if possible is never a bad idea, and we can do this conveniently by dropping e.g., one of the columns of the one-hot encoded variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size  price  classlabel  color_green  color_red\n",
       "0     2   10.1           0            1          0\n",
       "1     3   13.5           1            0          1\n",
       "2     5   15.3           0            0          0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are many different ways for dealing with missing data.\n",
    "- The simplest approaches are removing entire columns or rows.\n",
    "- Another simple approach is to impute missing values via the feature means, medians, mode, etc.\n",
    "- There is no rule or best practice, and the choice of the approprite missing data imputation method depends on your judgement and domain knowledge.\n",
    "- Below are some examples for dealing with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   NaN  8.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/missingdata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0\n",
       "B    0\n",
       "C    1\n",
       "D    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values per column:\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D\n",
       "0  1.0  2.0  3.0  4.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with missing values:\n",
    "\n",
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B\n",
       "0   1.0   2.0\n",
       "1   5.0   6.0\n",
       "2  10.0  11.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns with missing values:\n",
    "\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   NaN  8.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  2. ,  3. ,  4. ],\n",
       "       [ 5. ,  6. ,  7.5,  8. ],\n",
       "       [10. , 11. , 12. ,  6. ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X = df.values\n",
    "X = imputer.fit_transform(df.values)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation, Extraction, and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already covered very simple cases of feature transformation, i.e., normalization, that is, min-max scaling and standardization. There are many other cases, but an extensive coverage of feature preprocessing is beyond the scope of a machine learning class. However, we will will look at some popular feature selection (sequential feature selection) and feature extraction (e.g., principal component analysis) techniques later in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scikit-learn pipelines are an extremely convenient and powerful concept -- one of the things that sets scikit-learn apart from other machine learning libraries.\n",
    "- Pipelines basically let us define a series of perprocessing steps together with fitting an estimator.\n",
    "- Pipelines will automatically take care of pitfalls like estimating feature scaling parameters from the training set and applying those to scale new data (which we discussed earlier in the context of z-score standardization).\n",
    "- Below is an visualization of how pipelines work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sklearn-pipeline.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below is an example pipeline that combines the feature scaling step with the *k*NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     KNeighborsClassifier(n_neighbors=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('kneighborsclassifier', KNeighborsClassifier(n_neighbors=3))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 0, 0, 2, 1, 2, 0, 0, 2, 2, 1, 2, 1, 0, 0, 0, 0, 0, 2,\n",
       "       2, 1, 2, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see above, the Pipeline itself follows the scikit-learn estimator API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Also see the [FunctionTransformer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) in scikit-learn, which allows creating a transformer class from an arbitrary callable or function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro Model Selection -- Pipelines and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In machine learning practice, we often need to experiment with an machine learning algorithm's hyperparameters to find a good setting.\n",
    "- The process of tuning hyperparameters and comparing and selecting the resulting models is also called \"model selection\" (in contrast to \"algorithm selection\").\n",
    "- We will cover topics such as \"model selection\" and \"algorithm selection\" in more detail later in this course.\n",
    "- For now, we are introducing the simplest way of performing model selection: using the \"holdout method.\"\n",
    "- In the holdout method, we split a dataset into 3 subsets: a training, a validation, and a test datatset.\n",
    "- To avoid biasing the estimate of the generalization performance, we only want to use the test dataset once, which is why we use the validation dataset for hyperparameter tuning (model selection).\n",
    "- Here, the validation dataset serves as an estimate of the generalization performance, too, but it becomes more biased than the final estimate on the test data because of its repeated re-use during model selection (think of \"multiple hypothesis testing\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/holdout-tuning.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<mlxtend.evaluate.holdout.PredefinedHoldoutSplit object at 0x7fc5585a3df0>,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('kneighborsclassifier',\n",
       "                                        KNeighborsClassifier())]),\n",
       "             param_grid={'kneighborsclassifier__n_neighbors': [1, 3, 5],\n",
       "                         'kneighborsclassifier__p': [1, 2]})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.evaluate import PredefinedHoldoutSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "train_ind, valid_ind = train_test_split(np.arange(X.shape[0]),\n",
    "                                        test_size=0.2, shuffle=True,\n",
    "                                        random_state=123, stratify=y)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     KNeighborsClassifier())\n",
    "\n",
    "params = {'kneighborsclassifier__n_neighbors': [1, 3, 5],\n",
    "          'kneighborsclassifier__p': [1, 2]}\n",
    "\n",
    "split = PredefinedHoldoutSplit(valid_indices=valid_ind)\n",
    "\n",
    "grid = GridSearchCV(pipe,\n",
    "                    param_grid=params,\n",
    "                    cv=split)\n",
    "\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00109315, 0.00096583, 0.00098991, 0.001019  , 0.00093699,\n",
       "        0.00093198]),\n",
       " 'std_fit_time': array([0., 0., 0., 0., 0., 0.]),\n",
       " 'mean_score_time': array([0.00178385, 0.00256705, 0.00182605, 0.001647  , 0.00161791,\n",
       "        0.00220799]),\n",
       " 'std_score_time': array([0., 0., 0., 0., 0., 0.]),\n",
       " 'param_kneighborsclassifier__n_neighbors': masked_array(data=[1, 1, 3, 3, 5, 5],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kneighborsclassifier__p': masked_array(data=[1, 2, 1, 2, 1, 2],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'kneighborsclassifier__n_neighbors': 1,\n",
       "   'kneighborsclassifier__p': 1},\n",
       "  {'kneighborsclassifier__n_neighbors': 1, 'kneighborsclassifier__p': 2},\n",
       "  {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__p': 1},\n",
       "  {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__p': 2},\n",
       "  {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__p': 1},\n",
       "  {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__p': 2}],\n",
       " 'split0_test_score': array([0.9       , 0.96666667, 0.96666667, 0.93333333, 0.9       ,\n",
       "        0.9       ]),\n",
       " 'mean_test_score': array([0.9       , 0.96666667, 0.96666667, 0.93333333, 0.9       ,\n",
       "        0.9       ]),\n",
       " 'std_test_score': array([0., 0., 0., 0., 0., 0.]),\n",
       " 'rank_test_score': array([4, 1, 1, 3, 4, 4], dtype=int32)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "{'kneighborsclassifier__n_neighbors': 1, 'kneighborsclassifier__p': 2}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "clf = grid.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print('Test accuracy: %.2f%%' % (clf.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python Machine Learning 2nd ed.: Ch04 up to \"Selecting Meaningful Features\" (pg 107-123)\n",
    "- Python Machine Learning 2nd ed.: Ch06 up to \"Debugging algorithms with learning and validation curves\" (pg 185-194)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scikit-learn documentation: http://scikit-learn.org/stable/documentation.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
